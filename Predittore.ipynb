{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predittore.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiH7lSyCKkUq"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyh-IIOcfTpz"
      },
      "source": [
        "Classe predittore: \n",
        "- predizione_ultima_giornata_non_anomala: \n",
        "prende come **input** una riga dal file dati_riorganizzati che rappresenta un dataframe nel nuovo formato composto da tutte le normali prima di un'unica giornata anomala e un contatore utile per salvare l'immagine di output. \n",
        "Come **output** fornisce il confronto visivo  e la cosine distance tra la predizione effettuata su tutte le giornati normali precedenti all'ultima (normale) e quest'ultima.\n",
        "\n",
        "- predizione_giornata_anomala: stessi **input** del metodo predizione_ultima_giornata_non_anomala ma questa volta si shifta di una giornata, non considerando quindi la prima giornata normala e includendo l'ultima giornata normale. L'**output** è un confronto visivo e la cosine distance tra la predizione e la giornata anomala.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvSc5s_EGHe4"
      },
      "source": [
        "class Predittore:\n",
        "\n",
        "  def __init__(self,path):\n",
        "    self.path = path\n",
        "    \n",
        "  def predizione_ultima_giornata_non_anomala(self, dato, cont):\n",
        "\n",
        "    # per predire ultima giornata non anomala uno i valori che vanno da 0 a [(indice_giorno_anomalo - 1) - 23]\n",
        "    df_senza_anomalie = dato[dato[\"Anomalous\"] == 0]\n",
        "    df_target = df_senza_anomalie[0:-23] \n",
        "    df_da_predire = df_senza_anomalie[-23:]\n",
        "    #df_da_predire.to_csv(\"dapredire.csv\")\n",
        "    #df_target.to_csv(\"target.csv\")\n",
        "\n",
        "    n_input = 23\n",
        "    n_features = 1\n",
        "\n",
        "    del df_target[\"Index\"]\n",
        "    del df_target[\"Anomalous\"]\n",
        "    del df_target[\"Finestra\"]\n",
        "\n",
        "    train = df_target\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(train)\n",
        "    train = scaler.transform(train)\n",
        "\n",
        "    # parametri: batch_size=32, epochs = 100\n",
        "    generator = TimeseriesGenerator(train, train, length=n_input, batch_size=32)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(200, activation='relu', input_shape=(n_input, n_features)))\n",
        "    model.add(Dropout(0.15))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    model.fit(generator, epochs=90)\n",
        "\n",
        "    pred_list = []\n",
        "    batch = train[-n_input:].reshape((1, n_input, n_features))\n",
        "\n",
        "    for i in range(n_input):   \n",
        "      pred_list.append(model.predict(batch)[0]) \n",
        "      batch = np.append(batch[:,1:,:],[[pred_list[i]]],axis=1)\n",
        "\n",
        "    df_predict = pd.DataFrame(scaler.inverse_transform(pred_list), index=df_senza_anomalie[-n_input:].index, columns=['Prediction'])\n",
        "\n",
        "    plt.figure(figsize=(40,20))\n",
        "    plt.title(\"Confronto tra la giornata predetta e la giornata normale\")\n",
        "    plt.plot(df_predict.index, df_predict[\"Prediction\"], color='r', marker=\"o\")\n",
        "    plt.plot(df_da_predire.index,df_da_predire[\"Affluenza\"],color = \"b\",marker=\"o\")\n",
        "    plt.legend(loc='best', fontsize='small')\n",
        "    plt.xticks(fontsize=6)\n",
        "    plt.yticks(fontsize=18)\n",
        "    plt.xticks(rotation=70)\n",
        "\n",
        "    plt.savefig('confronto_normale' + str(cont) + '.png', bbox_inches='tight')\n",
        "\n",
        "    print(distance.cosine(df_predict[\"Prediction\"],df_da_predire[\"Affluenza\"]))\n",
        "\n",
        "\n",
        "  def predizione_giornata_anomala(self, dato, cont):\n",
        "  \n",
        "    # per predire la gioranta anomala dobbiamo prendere le giornate che vanno dalla seconda all'ultima normale\n",
        "    df_senza_anomalie = dato[dato[\"Anomalous\"] == 0]\n",
        "    df_giornata_anomala = dato[dato[\"Anomalous\"] == 1]\n",
        "\n",
        "    # tolgo la prima giornata\n",
        "    df_target = df_senza_anomalie[:23]\n",
        "\n",
        "    df_da_predire = df_senza_anomalie.drop(df_target.index)\n",
        "    # df_da_predire.to_csv(\"senza_anomalie.csv\")\n",
        "    \n",
        "    n_input = 23\n",
        "    n_features = 1\n",
        "\n",
        "    del df_da_predire[\"Index\"]\n",
        "    del df_da_predire[\"Anomalous\"]\n",
        "    del df_da_predire[\"Finestra\"]\n",
        "\n",
        "    train = df_da_predire\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(train)\n",
        "    train = scaler.transform(train)\n",
        "\n",
        "    # parametri: batch_size=32, epochs = 100\n",
        "    generator = TimeseriesGenerator(train, train, length=n_input, batch_size=32)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(200, activation='relu', input_shape=(n_input, n_features)))\n",
        "    model.add(Dropout(0.15))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    model.fit(generator, epochs=90)\n",
        "\n",
        "    pred_list = []\n",
        "    batch = train[-n_input:].reshape((1, n_input, n_features))\n",
        "\n",
        "    for i in range(n_input):   \n",
        "      pred_list.append(model.predict(batch)[0]) \n",
        "      batch = np.append(batch[:,1:,:],[[pred_list[i]]],axis=1)\n",
        "\n",
        "    df_predict = pd.DataFrame(scaler.inverse_transform(pred_list), index=df_da_predire[-n_input:].index, columns=['Prediction'])\n",
        "\n",
        "    plt.figure(figsize=(40,20))\n",
        "    plt.title(\"Confronto tra la giornata predetta e la giornata anomala\")\n",
        "    plt.plot(df_giornata_anomala.index, df_predict[\"Prediction\"], color='r', marker=\"o\")\n",
        "    plt.plot(df_giornata_anomala.index,df_giornata_anomala[\"Affluenza\"],color = \"b\",marker=\"o\")\n",
        "    plt.legend(loc='best', fontsize='small')\n",
        "    plt.xticks(fontsize=6)\n",
        "    plt.yticks(fontsize=18)\n",
        "    plt.xticks(rotation=70)\n",
        "\n",
        "    plt.savefig('confronto_anomalia' + str(cont) + '.png', bbox_inches='tight')\n",
        "\n",
        "    print(distance.cosine(df_predict[\"Prediction\"],df_giornata_anomala[\"Affluenza\"]))\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgdiCUe4e7o5"
      },
      "source": [
        "Semplice main che scorre i dati e li passa, un valore alla volta, al predittore."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aPK0-ttMjxf",
        "outputId": "57cf8764-aab3-41ec-ad8d-761850366ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "p = Predittore(\"dati_organizzati.pkl\")\n",
        "\n",
        "with open(\"dati_riorganizzati.pkl\",\"rb\") as f:\n",
        "  df_list = pickle.load(f)\n",
        "  cont = 0\n",
        "\n",
        "  for i in range(len(df_list)):\n",
        "    dato = df_list[i]\n",
        "\n",
        "    # 22 è il numero medio di giorni consecutivi normali, valore che usiamo come soglia per la dimensione minima della finestra\n",
        "    if dato[\"Finestra\"].max() > 22*23:\n",
        "      p.predizione_ultima_giornata_non_anomala(dato,cont)\n",
        "      p.predizione_giornata_anomala(dato,cont)\n",
        "\n",
        "      cont += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "39/39 [==============================] - 2s 43ms/step - loss: 0.1216\n",
            "Epoch 2/90\n",
            "39/39 [==============================] - 2s 44ms/step - loss: 0.0538\n",
            "Epoch 3/90\n",
            "39/39 [==============================] - 2s 44ms/step - loss: 0.0341\n",
            "Epoch 4/90\n",
            "39/39 [==============================] - 2s 42ms/step - loss: 0.0287\n",
            "Epoch 5/90\n",
            "39/39 [==============================] - 2s 41ms/step - loss: 0.0259\n",
            "Epoch 6/90\n",
            "39/39 [==============================] - 2s 42ms/step - loss: 0.0244\n",
            "Epoch 7/90\n",
            "39/39 [==============================] - 2s 43ms/step - loss: 0.0256\n",
            "Epoch 8/90\n",
            "39/39 [==============================] - 2s 42ms/step - loss: 0.0205\n",
            "Epoch 9/90\n",
            "39/39 [==============================] - 2s 41ms/step - loss: 0.0183\n",
            "Epoch 10/90\n",
            "39/39 [==============================] - 2s 42ms/step - loss: 0.0173\n",
            "Epoch 11/90\n",
            "39/39 [==============================] - 2s 47ms/step - loss: 0.0179\n",
            "Epoch 12/90\n",
            "39/39 [==============================] - 2s 45ms/step - loss: 0.0169\n",
            "Epoch 13/90\n",
            "39/39 [==============================] - 2s 45ms/step - loss: 0.0167\n",
            "Epoch 14/90\n",
            "39/39 [==============================] - 2s 45ms/step - loss: 0.0163\n",
            "Epoch 15/90\n",
            "39/39 [==============================] - 2s 45ms/step - loss: 0.0161\n",
            "Epoch 16/90\n",
            "39/39 [==============================] - 2s 45ms/step - loss: 0.0164\n",
            "Epoch 17/90\n",
            "39/39 [==============================] - 2s 43ms/step - loss: 0.0156\n",
            "Epoch 18/90\n",
            "39/39 [==============================] - 2s 42ms/step - loss: 0.0149\n",
            "Epoch 19/90\n",
            "39/39 [==============================] - 2s 43ms/step - loss: 0.0158\n",
            "Epoch 20/90\n",
            "39/39 [==============================] - 2s 44ms/step - loss: 0.0175\n",
            "Epoch 21/90\n",
            "39/39 [==============================] - 2s 42ms/step - loss: 0.0141\n",
            "Epoch 22/90\n",
            "39/39 [==============================] - 2s 43ms/step - loss: 0.0145\n",
            "Epoch 23/90\n",
            " 5/39 [==>...........................] - ETA: 1s - loss: 0.0197"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}