# -*- coding: utf-8 -*-
"""classificatoreMLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dnV2FxPA2c1C411peXL-ke6dm8xDvGkb
"""

import pandas as pd
from matplotlib import pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from keras.preprocessing.sequence import TimeseriesGenerator
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import make_classification
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout
import numpy as np
from scipy.spatial import distance
import warnings
warnings.filterwarnings("ignore")

"""Classe della preparazione dei dati:
- Prendo in ingresso il path dei dati da preparare e salva i csv dei dati opportunamente formattati pronti per essere usati dal predittore. In particolare aggiunge una colonna "Window" che rappresenta il numero di giorni normali che precedono un giorno anomalo. 
Questa colonna ha come valore di default "0" e contiene valori significativi solo nella prima entrata relativa ad un giorno anomalo.
"""

class dataPreprocessing:

  def __init__(self,dataPath):
    self.dataPath = dataPath
  
  def prepare_data(self):

    df = pd.read_csv(self.dataPath)
    count = 0
    # mantiene il numero di giorni normali che precedono un giorno anomalo
    window_normal_day = []

    for row in df.itertuples():
      if row[3] == 0:
        count+=1
        window_normal_day.append(0)
      else: 
        window_normal_day.append(count)
        count = 0

    df["Window"] = window_normal_day
    df.to_csv("window.csv")

    count = 0

    for row in df.itertuples():
      if (row[3] == 1) & (row[4] != 0):
        # considero i giorni normali precedenti più il giorno anomalo attuale
        df_target = df.iloc[row[0] - row[4] : row[0] + 23]
        # salvo ogni dataframe in modo separato
        df_target.to_csv("dati" + str(count) + ".csv")
        count = count + 1
    
    # ritorno il numero di dataframe prodotti
    return count

"""Classe predittore: 
- predizione_giornata_normale: 
prende come **input** una riga dal file dati_riorganizzati che rappresenta un dataframe nel nuovo formato composto da tutte le normali prima di un'unica giornata anomala e un contatore utile per salvare l'immagine di output. 
Come **output** fornisce il confronto visivo  e la cosine distance tra la predizione effettuata su tutte le giornati normali precedenti all'ultima (normale) e quest'ultima.

- predizione_giornata_anomala: stessi **input** del metodo predizione_ultima_giornata_non_anomala ma questa volta si shifta di una giornata, non considerando quindi la prima giornata normala e includendo l'ultima giornata normale. L'**output** è un confronto visivo e la cosine distance tra la predizione e la giornata anomala.
"""

class hotspotFlowPrediction:

  def __init__(self,dataPath):
    self.dataPath = dataPath
    self.cosine_distance = []
    self.index = []
    self.anomalous = []
    
  def predizione_giornata_normale(self, toAnalyze, count):

    # per predire ultima giornata non anomala uno i valori che vanno da 0 a [(indice_giorno_anomalo - 1) - 23]
    df_without_anomalies = toAnalyze[toAnalyze["Anomalous"] == 0]
    df_target = df_without_anomalies[0:-23] 
    df_to_predict = df_without_anomalies[-23:]

    n_input = 23
    n_features = 1

    # tolgo le colonne che non mi interessano adesso
    del df_target["Index"]
    del df_target["Anomalous"]
    del df_target["Window"]

    print(df_to_predict)

    train = df_target
    scaler = MinMaxScaler()
    scaler.fit(train)
    train = scaler.transform(train)

    # parametri: batch_size=32, epochs=100
    generator = TimeseriesGenerator(train, train, length=n_input, batch_size=32)
    model = Sequential()
    model.add(LSTM(200, activation='relu', input_shape=(n_input, n_features)))
    model.add(Dropout(0.15))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    model.fit(generator, epochs=90)

    pred_list = []
    batch = train[-n_input:].reshape((1, n_input, n_features))

    for i in range(n_input):   
      pred_list.append(model.predict(batch)[0]) 
      batch = np.append(batch[:,1:,:],[[pred_list[i]]],axis=1)

    df_predict = pd.DataFrame(scaler.inverse_transform(pred_list), index=df_without_anomalies[-n_input:].index, columns=['Prediction'])

    plt.figure(figsize=(40,20))
    plt.title("Confronto tra la giornata predetta e la giornata normale")
    plt.plot(df_predict.index, df_predict["Prediction"], color='r', marker="o")
    plt.plot(df_to_predict.index,df_to_predict["Affluenza"],color = "b",marker="o")
    plt.legend(loc='best', fontsize='small')
    plt.xticks(fontsize=6)
    plt.yticks(fontsize=18)
    plt.xticks(rotation=70)

    # salvo l'immagine del confronto
    plt.savefig('confronto_normale' + str(count) + '.png', bbox_inches='tight')

    # stampo a video e salvo la cosine distance
    print("Cosine distance: " + str(distance.cosine(df_predict["Prediction"],df_to_predict["Affluenza"])))
    self.index.append(df_to_predict["Index"].max())
    self.cosine_distance.append(distance.cosine(df_predict["Prediction"],df_to_predict["Affluenza"]))
    self.anomalous.append(0)


  def predizione_giornata_anomala(self, toAnalyze, count):
  
    # per predire la gioranta anomala dobbiamo prendere le giornate che vanno dalla seconda all'ultima normale
    df_without_anomalies = toAnalyze[toAnalyze["Anomalous"] == 0]
    df_anomalous_day = toAnalyze[toAnalyze["Anomalous"] == 1]

    # tolgo la prima giornata
    df_target = df_without_anomalies[:23]

    df_to_predict = df_without_anomalies.drop(df_target.index)

    n_input = 23
    n_features = 1

    # tolgo le colonne che non mi servono
    del df_to_predict["Index"]
    del df_to_predict["Anomalous"]
    del df_to_predict["Window"]

    print(df_anomalous_day)

    train = df_to_predict
    scaler = MinMaxScaler()
    scaler.fit(train)
    train = scaler.transform(train)

    # parametri: batch_size=32, epochs=100
    generator = TimeseriesGenerator(train, train, length=n_input, batch_size=32)
    model = Sequential()
    model.add(LSTM(200, activation='relu', input_shape=(n_input, n_features)))
    model.add(Dropout(0.15))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    model.fit(generator, epochs=90)

    pred_list = []
    batch = train[-n_input:].reshape((1, n_input, n_features))

    for i in range(n_input):   
      pred_list.append(model.predict(batch)[0]) 
      batch = np.append(batch[:,1:,:],[[pred_list[i]]],axis=1)

    df_predict = pd.DataFrame(scaler.inverse_transform(pred_list), index=df_to_predict[-n_input:].index, columns=['Prediction'])

    plt.figure(figsize=(40,20))
    plt.title("Confronto tra la giornata predetta e la giornata anomala")
    plt.plot(df_anomalous_day.index, df_predict["Prediction"], color='r', marker="o")
    plt.plot(df_anomalous_day.index,df_anomalous_day["Affluenza"],color = "b",marker="o")
    plt.legend(loc='best', fontsize='small')
    plt.xticks(fontsize=6)
    plt.yticks(fontsize=18)
    plt.xticks(rotation=70)

    plt.savefig('confronto_anomalia' + str(count) + '.png', bbox_inches='tight')
    
    print("Cosine distance: " + str(distance.cosine(df_predict["Prediction"],df_anomalous_day["Affluenza"])))
    self.index.append(df_anomalous_day["Index"].max())
    self.cosine_distance.append(distance.cosine(df_predict["Prediction"],df_anomalous_day["Affluenza"]))
    self.anomalous.append(1)

"""Classe del classificatore:
- classify_data: metodo che prende in ingresso i dati preparati e il valore di max_iter inserito dall'utente e stampa come output lo score della predizione e la predizione delle label "Anomalous".
"""

class dataClassifier:

  def __init__(self,predictor,max_iter):
    self.predictor = predictor
    self.max_iter = max_iter

  def classify_data(self):
    
    df = pd.DataFrame(self.predictor.cosine_distance,columns=["Cosine distance"],index=self.predictor.index)
    df["Anomali reali"] = self.predictor.anomalous

    X = np.array(self.predictor.cosine_distance).reshape(-1,1)
    y = self.predictor.anomalous

    # parametri della classificazione: max_iter= passato dall'utente, hidden_layer_size = (100,100)
    clf = MLPClassifier(max_iter = int(self.max_iter),hidden_layer_sizes=(100,100))
    clf.fit(X,y)

    # predizione e print dello score
    predicted = clf.predict(X)
    print("Score: %f" % clf.score(X, y))
    
    df["Anomalie predette"] = predicted
    print(df)

"""Interfaccia da linea di comando che permette di inserire i parametri necessari."""

class anomalyDetector:

  def __init__(self):
    self.dataPath = input('Inserisci il path dei dati da analizzare: ')
    self.max_iter = input("Inserisci il max_iter da usare: ")

  def predictHotspotFlow(self):
    self.predictor = hotspotFlowPrediction(self.dataPath)
  
  def preprocessData(self):
    self.preprocessing = dataPreprocessing(self.dataPath)
    # quanti dataframe sono stati preparati dal preprocessatore
    self.howManyDfToAnalyze = self.preprocessing.prepare_data()

  def detectAnomalies(self):
    self.predictHotspotFlow()
    self.preprocessData()

    counter = 0

    for i in range(self.howManyDfToAnalyze):
      with open("dati" + str(i) + ".csv") as f:
        df_to_analyze = pd.read_csv(f,index_col="Unnamed: 0")

        # 10 è il valore di soglia che permette di considerare 6 giorni anomali su 9 
        # con una discreta precisione
        if df_to_analyze["Window"].max() >= 10*23:
          self.predictor.predizione_giornata_normale(df_to_analyze,counter)
          self.predictor.predizione_giornata_anomala(df_to_analyze,counter)

        counter += 1

    c = dataClassifier(self.predictor,self.max_iter)
    c.classify_data()

"""Creazione dell'istanza di una classe di Interfaccia."""

cli = anomalyDetector()
cli.detectAnomalies()