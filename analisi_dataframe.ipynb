{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analisi_dataframe.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJTJvHchedLv",
        "colab_type": "text"
      },
      "source": [
        "Caricare il csv come dataframe e mettere ad 1 le i valori della colonna \"Anomalous\" delle giornate riportate nella tabella del documento docx in allegato."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7SE45-xfYrI",
        "colab_type": "text"
      },
      "source": [
        "Apro il csv dei dati e con questo creo un dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDFiouGYeqiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "csv_path = 'timeSeries2015HotspotD.csv'\n",
        "with open(csv_path) as csv_file:\n",
        "  csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "\n",
        "  df = pd.read_csv(csv_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcL-PFzmfQq0",
        "colab_type": "text"
      },
      "source": [
        "Apro il file Excel con le tabelle delle anomalie suddivise per Cluster e con questo creo 3 dataframe separati."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoyoOfPGfRHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "excel_path = 'doc-convertiti.xlsx'\n",
        "\n",
        "cluster0 = pd.read_excel(excel_path, sheet_name='Cluster0', usecols=['Data', 'Cluster'])\n",
        "cluster1 = pd.read_excel(excel_path, sheet_name='Cluster1', usecols=['Data', 'Cluster'])\n",
        "cluster2 = pd.read_excel(excel_path, sheet_name='Cluster2', usecols=['Data', 'Cluster'])\n",
        "\n",
        " cluster0[\"Data\"] = pd.to_datetime(cluster0[\"Data\"])\n",
        "  cluster1[\"Data\"] = pd.to_datetime(cluster1[\"Data\"])\n",
        "  cluster2[\"Data\"] = pd.to_datetime(cluster2[\"Data\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jk5cOUEgdV6",
        "colab_type": "text"
      },
      "source": [
        "Itero i dataframe per settare il valore di Anomalous e salvo il relativo .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX_RH5mQgsBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, j in df.iterrows():\n",
        "    for k in cluster0[\"Data\"]:\n",
        "        if k.day == j['Day'] and k.month == j['Month'] and j['Cluster'] == 0:\n",
        "            df.at[i, 'Anomalous'] = 1\n",
        "\n",
        "    for k in cluster1[\"Data\"]:\n",
        "        if k.day == j['Day'] and k.month == j['Month'] and j['Cluster'] == 1:               \n",
        "            df.at[i, 'Anomalous'] = 1\n",
        "\n",
        "    for k in cluster2[\"Data\"]:\n",
        "        if k.day == j['Day'] and k.month == j['Month'] and j['Cluster'] == 2:\n",
        "            df.at[i, 'Anomalous'] = 1\n",
        "\n",
        "df.to_csv('out1.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlodkL1chBAR",
        "colab_type": "text"
      },
      "source": [
        "Eliminare dal dataframe (risultante dal punto 1) tutte le righe con Anomalous a 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rc6ksRjhE0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out1_path = 'out1.csv'\n",
        "with open(out1_path) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    df = pd.read_csv(out1_path)\n",
        "\n",
        "    for i, j in df.iterrows():\n",
        "        if df.at[i, 'Anomalous'] == 1:\n",
        "            df.drop(i, inplace=True)\n",
        "\n",
        "    df.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
        "\n",
        "    df.to_csv('out2.csv', index=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSbef8iyhY5D",
        "colab_type": "text"
      },
      "source": [
        "Apro il csv salvato in precedenza e creo dataframe separati per la X e la Y della classificazione.\n",
        "Creo successivamente un oggetto Random Forest per eseguire la classificazione dei cluster e ne calcolo la precisione."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXiY_oW5hZER",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a417884-bc33-4071-c345-4b5dc9d89910"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "out2_path = 'out2.csv'\n",
        "with open(out2_path) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    df = pd.read_csv(out2_path)\n",
        "\n",
        "    target_cols = ['Cluster']\n",
        "    data_cols = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'h8', 'h9', 'h10', 'h11', 'h12', 'h13', 'h14',\n",
        "                'h15', 'h16', 'h17', 'h18', 'h19', 'h20', 'h21', 'h22', 'h23']\n",
        "\n",
        "    X = df[data_cols]\n",
        "    Y = df[target_cols]\n",
        "\n",
        "    X, y = make_classification(n_samples=328)\n",
        "\n",
        "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    Y_pred = clf.predict(X)\n",
        "\n",
        "    print(\"Precisione:\", clf.score(X, Y, sample_weight=None))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisione: 0.4634146341463415\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}